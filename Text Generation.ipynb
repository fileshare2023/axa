{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eb15f8-c230-44d8-a374-abed71e1c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers gradio torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a587dca7-5a80-4190-8c5f-a7da0c04a6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sriam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\sriam\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "# Importing Required Libraries\n",
    "import gradio as gr\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954c75fb-28c7-48e3-bd49-05a2a9df1fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436558f8-6a40-4cd6-8821-805cb18155e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(prompt):\n",
    "    \"\"\"\n",
    "    Generates text based on an input prompt using the pre-trained GPT-2 model.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Input text prompt for text generation.\n",
    "\n",
    "    Returns:\n",
    "        str: Generated text based on the prompt.\n",
    "    \"\"\"\n",
    "    # Tokenize the input prompt\n",
    "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate text\n",
    "    outputs = model.generate(inputs, max_length=100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "    \n",
    "    # Decode the generated tokens to get the generated text\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a3192d4-1a09-44fc-a13a-851b4969233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching Gradio Interface...\n",
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gradio_interface():\n",
    "    \"\"\"\n",
    "    Creates a Gradio interface for the text generation model.\n",
    "\n",
    "    Returns:\n",
    "        gr.Interface: A Gradio interface object.\n",
    "    \"\"\"\n",
    "    description = \"Enter a text prompt, and the model will generate text based on the given input using GPT-2.\"\n",
    "    interface = gr.Interface(\n",
    "        fn=generate_text,\n",
    "        inputs=gr.Textbox(label=\"Input Text Prompt\"),\n",
    "        outputs=gr.Textbox(label=\"Generated Text\"),\n",
    "        title=\"GPT-2 Text Generation\",\n",
    "        description=description,\n",
    "    )\n",
    "    return interface\n",
    "\n",
    "# Launch the Application\n",
    "# -------------------------------\n",
    "# Launch the Gradio interface.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Launching Gradio Interface...\")\n",
    "    app = gradio_interface()\n",
    "    app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4387b-8489-4742-91be-fb9dfb7cb95a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
